{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNWNf1fu/YSViLmMg18GRnI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamgorny/neural_networks/blob/main/CNN_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries needed for the task:\n"
      ],
      "metadata": {
        "id": "siyTWlIMxdoW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVw-sg_sXUvQ"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download datasets:"
      ],
      "metadata": {
        "id": "yLWefkxSxxQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/esmartdata-courses-files/ann-course/flying-vehicles.zip\n",
        "!unzip -q flying-vehicles.zip"
      ],
      "metadata": {
        "id": "9UKkMh22wks6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare directories:"
      ],
      "metadata": {
        "id": "OlcX_c9jx8MJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./images\n",
        "\n",
        "base_dir = './data/planes'\n",
        "data_dir = './images'\n",
        "\n",
        "raw_no_of_files = {}\n",
        "classes = ['drone', 'fighter-jet', 'helicopter', 'missile', 'passenger-plane', 'rocket']\n",
        "# Iterate over classes and get the size of each dataset.\n",
        "for dir in classes:\n",
        "    raw_no_of_files[dir] = len(os.listdir(os.path.join(base_dir, dir)))\n",
        "\n",
        "raw_no_of_files.items()\n",
        "\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "\n",
        "# Training dataset\n",
        "train_dir = os.path.join(data_dir, 'train')    \n",
        "# Validation dataset\n",
        "valid_dir = os.path.join(data_dir, 'valid')    \n",
        "# Testing dataset\n",
        "test_dir = os.path.join(data_dir, 'test')     \n",
        "\n",
        "train_helicopter_dir = os.path.join(train_dir, 'helicopter')\n",
        "train_missile_dir = os.path.join(train_dir, 'missile')\n",
        "\n",
        "valid_helicopter_dir = os.path.join(valid_dir, 'helicopter')\n",
        "valid_missile_dir = os.path.join(valid_dir, 'missile')\n",
        "\n",
        "test_helicopter_dir = os.path.join(test_dir, 'helicopter')\n",
        "test_missile_dir = os.path.join(test_dir, 'missile')\n",
        "\n",
        "data_dirs = [train_helicopter_dir, train_missile_dir, valid_helicopter_dir, valid_missile_dir, test_helicopter_dir, test_missile_dir]\n",
        "\n",
        "for directory in (train_dir, valid_dir, test_dir):\n",
        "    if not os.path.exists(directory):\n",
        "        os.mkdir(directory)\n",
        "\n",
        "for dir in data_dirs:\n",
        "    if not os.path.exists(dir):\n",
        "        os.mkdir(dir)        "
      ],
      "metadata": {
        "id": "ynwB6zxyw27a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter dataset and exclude files with extensions other that *.jpg*, *.png* or *.jpeg*:"
      ],
      "metadata": {
        "id": "gFtmB5_v2LmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "helicopter_filenames = os.listdir(os.path.join(base_dir, 'helicopter'))\n",
        "missile_filenames = os.listdir(os.path.join(base_dir, 'missile'))\n",
        "\n",
        "helicopter_filenames = [filename for filename in helicopter_filenames if filename.split('.')[1].lower() in ['jpg', 'png', 'jpeg']]\n",
        "missile_filenames = [filename for filename in missile_filenames if filename.split('.')[1].lower() in ['jpg', 'png', 'jpeg']]"
      ],
      "metadata": {
        "id": "5uktb_9NzfnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate index of last file for each dataset:"
      ],
      "metadata": {
        "id": "cme-0i70CvEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size = min(len(helicopter_filenames), len(missile_filenames))\n",
        "\n",
        "train_size = int(np.floor(0.7 * size))\n",
        "valid_size = int(np.floor(0.2 * size))\n",
        "test_size = size - train_size - valid_size\n",
        "\n",
        "train_idx = train_size\n",
        "valid_idx = train_size + valid_size\n",
        "test_idx = train_size + valid_size + test_size\n"
      ],
      "metadata": {
        "id": "2OM9-ql36-CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divide files between train, validation and test datasets:"
      ],
      "metadata": {
        "id": "fIRqNNk_Co73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, fname in enumerate(helicopter_filenames):\n",
        "    if i <= train_idx:\n",
        "        src = os.path.join(base_dir, 'helicopter', fname)\n",
        "        dst = os.path.join(train_helicopter_dir, fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "    elif train_idx < i <= valid_idx:\n",
        "        src = os.path.join(base_dir, 'helicopter', fname)\n",
        "        dst = os.path.join(valid_helicopter_dir, fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "    elif valid_idx < i < test_idx:\n",
        "        src = os.path.join(base_dir, 'helicopter', fname)\n",
        "        dst = os.path.join(test_helicopter_dir, fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "for i, fname in enumerate(missile_filenames):\n",
        "    if i <= train_idx:\n",
        "        src = os.path.join(base_dir, 'missile', fname)\n",
        "        dst = os.path.join(train_missile_dir, fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "    elif train_idx < i <= valid_idx:\n",
        "        src = os.path.join(base_dir, 'missile', fname)\n",
        "        dst = os.path.join(valid_missile_dir, fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "    elif valid_idx < i < test_idx:\n",
        "        src = os.path.join(base_dir, 'missile', fname)\n",
        "        dst = os.path.join(test_missile_dir, fname)\n",
        "        shutil.copyfile(src, dst) \n",
        "\n",
        "print('Helicopter - training set size: ', len(os.listdir(train_helicopter_dir)))\n",
        "print('Helicopter - validation set size: ', len(os.listdir(valid_helicopter_dir)))\n",
        "print('Helicopter - test set size: ', len(os.listdir(test_helicopter_dir)))\n",
        "\n",
        "print('Missile - training set size: ', len(os.listdir(train_missile_dir)))\n",
        "print('Missile - validation set size: ', len(os.listdir(valid_missile_dir)))\n",
        "print('Missile - test set size: ', len(os.listdir(test_missile_dir)))             "
      ],
      "metadata": {
        "id": "FwZSpqTU9AUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pick and index of an helicopter image from the training dataset:\n",
        "\n",
        "idx = 380 #@param {type:'slider', min:0, max:919}\n",
        "names_mapping = dict(enumerate(helicopter_filenames))\n",
        "img_path = os.path.join(train_helicopter_dir, names_mapping[idx])\n",
        "\n",
        "img = image.load_img(img_path)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.grid(False)\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "wpnUNEMED2qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pick and index of an missile image from the training dataset:\n",
        "\n",
        "idx = 239 #@param {type:'slider', min:0, max:919}\n",
        "names_mapping = dict(enumerate(missile_filenames))\n",
        "img_path = os.path.join(train_missile_dir, names_mapping[idx])\n",
        "\n",
        "img = image.load_img(img_path)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.grid(False)\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "nPOete1IEWaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation:"
      ],
      "metadata": {
        "id": "ZQ59swyLFBgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_generator = ImageDataGenerator(\n",
        "    rotation_range=40,     # the range of random rotation of an image\n",
        "    rescale=1./255.,\n",
        "    width_shift_range=0.2,  # the range of horizontal shift of an image\n",
        "    height_shift_range=0.2, # the range of vertical shift of an image\n",
        "    shear_range=0.2,        # the range of random shear of an image\n",
        "    zoom_range=0.2,         # the range of random zoom of an image\n",
        "    horizontal_flip=True,   # should the image be flipped horizontally\n",
        "    fill_mode='nearest'     # how to deal with new pixels created during the image transformation\n",
        ")\n",
        "\n",
        "# rescale all the images by 1/255 bias.\n",
        "validation_data_generator = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "train_generator = training_data_generator.flow_from_directory(directory=train_dir,\n",
        "                                                   target_size=(150, 150),\n",
        "                                                   batch_size=32,\n",
        "                                                   class_mode='binary')\n",
        "\n",
        "valid_generator = validation_data_generator.flow_from_directory(directory=valid_dir,\n",
        "                                                   target_size=(150, 150),\n",
        "                                                   batch_size=32,\n",
        "                                                   class_mode='binary')"
      ],
      "metadata": {
        "id": "ixUNvf0uFDS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_augmented_images(directory, idx):\n",
        "    \"\"\"\n",
        "    The function returns the plot with example images\n",
        "    created with the data augmentation technique.\n",
        "    \"\"\"\n",
        "    file_names = [os.path.join(directory, file_name) for file_name in os.listdir(directory)]\n",
        "    img_path = file_names[idx]\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, 0)\n",
        "    # we can also use x = x.reshape((1, ) + x.shape)\n",
        "    print(x.shape)\n",
        "    i = 1\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    for batch in training_data_generator.flow(x, batch_size=1):\n",
        "        plt.subplot(3, 4, i)\n",
        "        plt.grid(False)\n",
        "        imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "        i += 1\n",
        "        if i % 13 == 0:\n",
        "            break"
      ],
      "metadata": {
        "id": "I_pscgH1nDyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Helicopter dataset:\n",
        "idx = 467 #@param {type:'slider', min:0, max:919}            \n",
        "display_augmented_images(train_helicopter_dir, idx)"
      ],
      "metadata": {
        "id": "M2HOHnR2m5-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building model:"
      ],
      "metadata": {
        "id": "varvqatmqnDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units=1024, activation='relu'))\n",
        "model.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "m87azInVqmMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizers.RMSprop(learning_rate=0.01),\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1xnS3x4zq20g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "steps_per_epoch = train_size // batch_size\n",
        "validation_steps = valid_size // batch_size\n",
        "\n",
        "history = model.fit_generator(generator=train_generator,\n",
        "                             steps_per_epoch=steps_per_epoch,\n",
        "                             epochs=30,    # 100\n",
        "                             validation_data=valid_generator,\n",
        "                             validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "z4nB6zsYrzJH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}